# Fashion-MNIST_MIPT_DS_2025_Fede_VV_kaggle
Kaggle Competitions for MIPT_DS_2025 

# Fashion-MNIST Classification Challenge

Этот репозиторий содержит решение учебного соревнования на Kaggle по классификации изображений одежды из датасета Fashion-MNIST с использованием сверточных нейронных сетей на TensorFlow/Keras.

[Ссылка на соревнование](https://www.kaggle.com/competitions/mipt-bio-2025/data)

## Оглавление

- [Описание проекта](#описание-проекта)
- [Структура репозитория](#структура-репозитория)
- [Требования](#требования)
- [Подготовка данных](#подготовка-данных)
- [Запуск ноутбука](#запуск-ноутбука)
- [Архитектура модели](#архитектура-модели)
- [Аугментация и колбэки](#аугментация-и-колбэки)
- [Обучение и оценка](#обучение-и-оценка)
- [Формирование сабмишена](#формирование-сабмишена)
- [Результаты](#результаты)
- [Лицензия](#лицензия)
- [Контакты](#контакты)

## Описание проекта

Задача: построить CNN-модель, которая на Public Leaderboard Kaggle достигает accuracy ≥ 0.8 на датасете Fashion-MNIST. Датасет содержит 28×28 изображений предметов одежды (10 классов).

## Структура репозитория

```
├── README.md             # этот файл
├── notebook.ipynb        # Jupyter Notebook с решением
├── submission.csv        # итоговый файл для Kaggle
├── best_fmnist.h5        # сохранённые веса лучшей модели
└── requirements.txt      # зависимости проекта
```

## Требования

- Python 3.7+
- TensorFlow 2.x
- scikit-learn
- pandas
- matplotlib

Установить зависимости можно командой:

```bash
pip install -r requirements.txt
```

## Подготовка данных

1. Скачайте датасеты с Kaggle или используйте предоставленный путь `/kaggle/input/...`.
2. Файлы:
   - `fmnist_train.csv` — обучающая выборка с метками.
   - `fmnist_test.csv` — тестовая выборка без меток.
   - `sample_submission.csv` — пример формата ответа.

## Запуск ноутбука

1. Откройте `notebook.ipynb` в Jupyter или Kaggle Kernels.
2. Поочерёдно выполните ячейки:
   - Импорты и просмотр файлов.
   - Загрузка и очистка данных.
   - EDA: визуализация примеров.
   - Определение и компиляция модели.
   - Подготовка аугментации и колбэков.
   - Обучение модели.
   - Формирование и сохранение `submission.csv`.

## Архитектура модели

- Два свёрточных блока с BatchNormalization и Dropout.
- Полносвязный слой 256 + BatchNormalization + Dropout.
- Выходной слой softmax на 10 классов.

## Аугментация и колбэки

- **Аугментация**: случайные повороты, сдвиги, зум, сдвиг по высоте/ширине, горизонтальное отражение.
- **Колбэки**:
  - `ReduceLROnPlateau` — снижение скорости обучения при стагнации валидационной метрики.
  - `ModelCheckpoint` — сохранение лучшей модели по `val_accuracy`.
  - `EarlyStopping` — ранняя остановка с возвращением лучших весов.

## Обучение и оценка

- Разбиение тренировочного набора на train/validation в пропорции 90/10.
- Обучение в потоках аугментации до 50 эпох с мониторингом валидации.

## Формирование сабмишена

После обучения выполняется предсказание на тестовом наборе, выбираются классы по максимальному softmax-выходу и формируется `submission.csv`:

```python
submission = pd.DataFrame({
    'Id': test['Id'],
    'label': labels
})
submission.to_csv('submission.csv', index=False)
```

## Результаты

- Достигнутая точность на Public Leaderboard: **0.8+**.

## Лицензия

Этот проект распространяется под лицензией MIT.

## Контакты

Автор: [Василий Феде]
Email: protos.dota@gmail.com
GitHub: https://github.com/FedeVas
